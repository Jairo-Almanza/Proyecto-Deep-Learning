{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeNaxoA43uZO"
      },
      "source": [
        "# Proyecto clasificación de imágenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "irW7iozQ3uZP"
      },
      "outputs": [],
      "source": [
        "# Bibliotecas necesarias\n",
        "\n",
        "import json\n",
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = '/content'"
      ],
      "metadata": {
        "id": "Q1qCN7O54sM3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cargamos Kaggle y a travez de la Api descargamos el conjunto de datos"
      ],
      "metadata": {
        "id": "dfbgShyuyhjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!touch '/root/.kaggle/kaggle.json'"
      ],
      "metadata": {
        "id": "_Zs6Z4xx5JiG",
        "outputId": "6a436b8c-c2df-403b-a3e2-14775b9c2a44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Appi token\n",
        "api_token = {\"username\":\"jairoalmanza\",\"key\":\"4054e3a9b3a8e7c76e969e3fa1132644\"}"
      ],
      "metadata": {
        "id": "2lIGXUzz5eel"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/root/.kaggle/kaggle.json\", \"w\") as file:\n",
        " json.dump(api_token, file)\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "n0IheaoT5z9V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargar data\n",
        "!kaggle competitions download -c dogs-vs-cats"
      ],
      "metadata": {
        "id": "sn4XaYSg57W8",
        "outputId": "7019914e-d936-41db-f647-a85a64d8121a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dogs-vs-cats.zip to /content\n",
            " 97% 785M/812M [00:03<00:00, 265MB/s]\n",
            "100% 812M/812M [00:04<00:00, 209MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraer data de zip\n",
        "for file in os.listdir():\n",
        " if file.endswith(\".zip\"):\n",
        "  zip_ref = zipfile.ZipFile(file, \"r\")\n",
        "  zip_ref.extractall()\n",
        "  zip_ref.close()"
      ],
      "metadata": {
        "id": "-xIMBQLo6Hzk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "# Define los caminos a los archivos zip\n",
        "train_zip_path = '/content/train.zip'\n",
        "test_zip_path = '/content/test1.zip'\n",
        "# Define los directorios donde se descomprimirán los archivos\n",
        "train_dir = '/content'\n",
        "test_dir = '/content'\n",
        "# Función para descomprimir archivos zip\n",
        "def unzip_file(zip_path, extract_to):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "# Descomprime los archivos zip\n",
        "unzip_file(train_zip_path, train_dir)\n",
        "unzip_file(test_zip_path, test_dir)"
      ],
      "metadata": {
        "id": "OmhHL1iT6jwk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carga del conjunto de datos\n",
        "\n",
        "Datos de train"
      ],
      "metadata": {
        "id": "L0QZymfLtT9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the directory path where your images are located\n",
        "image_dir = '/content/train/'\n",
        "\n",
        "# Create a list to store the image vectors. Conjunto X_train\n",
        "X_train = []\n",
        "im=0\n",
        "# Loop through all the images in the directory\n",
        "for filename in os.listdir(image_dir):\n",
        "    im+=1\n",
        "    print(f'imagen: {im}', end='\\r')\n",
        "\n",
        "    if filename.endswith(\".jpg\"):\n",
        "\n",
        "        # Open the image using PIL\n",
        "        img = Image.open(os.path.join(image_dir, filename))\n",
        "\n",
        "        # Resize the image to 200x200 pixels\n",
        "        img = img.resize((200, 200))\n",
        "\n",
        "        # Convirtiendo la imagen to a numpy array\n",
        "        img_array = np.array(img)\n",
        "\n",
        "        # Reshape la imagen en la forma adecuada para el modelo\n",
        "        img_tensor = img_array.reshape((200, 200, 3))\n",
        "\n",
        "        # Append the vector to the list\n",
        "        X_train.append(img_tensor)\n",
        "\n",
        "# Convert the list to a numpy array\n",
        "X_train = np.array(X_train)\n",
        "\n",
        "print(X_train.shape)"
      ],
      "metadata": {
        "id": "GTaQq0Av9qob",
        "outputId": "0882b365-c43b-4919-c4fa-3622381b7ef4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000, 200, 200, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizar X_train\n",
        "X_train = np.divide(X_train, 255.0)"
      ],
      "metadata": {
        "id": "jDPzayH1qfVe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store labels. Si imagen Cat entonces y=1 si no 0 / Si imagen Dog entonces y=1 si no 0\n",
        "y_train = []\n",
        "\n",
        "for file in os.listdir(image_dir):\n",
        "    # Check if the file is an image\n",
        "    if file.endswith('.jpg'):\n",
        "        # Create the label\n",
        "        if file.startswith('cat'):\n",
        "            y_train.append([1, 0])\n",
        "        elif file.startswith('dog'):\n",
        "            y_train.append([0, 1])\n",
        "\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "iCmB5g0gtLf9",
        "outputId": "99578591-c3e3-4ae4-f4a7-506a1cb47fe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datos de Test"
      ],
      "metadata": {
        "id": "3z9Gkex8tbVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the directory path where your images are located\n",
        "image_dir_test = '/content/test1/'\n",
        "\n",
        "# Create a list to store the image vectors. Conjunto X_train\n",
        "X_test = []\n",
        "im1=0\n",
        "# Loop through all the images in the directory\n",
        "for filename_ts in os.listdir(image_dir_test):\n",
        "    im1+=1\n",
        "    print(f'imagen: {im1}', end='\\r')\n",
        "    if filename_ts.endswith(\".jpg\"):\n",
        "        # Open the image using PIL\n",
        "        imgts = Image.open(os.path.join(image_dir_test, filename_ts))\n",
        "\n",
        "        # Resize the image to 200x200 pixels (just in case)\n",
        "        imgts = imgts.resize((200, 200))\n",
        "\n",
        "        # Convert the image to a numpy array\n",
        "        img_arrayts = np.array(imgts)\n",
        "\n",
        "        # Reshape la imagen en la forma adecuada para el modelo\n",
        "        img_tensorts = img_arrayts.reshape((200, 200, 3))\n",
        "\n",
        "        # Append the vector to the list\n",
        "        X_test.append(img_tensorts)\n",
        "\n",
        "# Convert the list to a numpy array\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "8TwOrKh0tdeE",
        "outputId": "d3e597f3-64fc-4c9f-e7a3-1e103b225030",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12500, 200, 200, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizar X_test\n",
        "X_test = np.divide(X_test, 255.0)"
      ],
      "metadata": {
        "id": "ph-gSOnRt6gV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('X_train.npy', X_train)\n",
        "np.save('y_train.npy', y_train)\n",
        "np.save('X_test.npy', X_test)"
      ],
      "metadata": {
        "id": "nnoeKbtnuFWk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construye una RNA"
      ],
      "metadata": {
        "id": "sWozYTaPyQCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "model.add(Conv2D(input_shape=(200, 200, 3), filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=4096, activation=\"relu\"))\n",
        "model.add(Dense(units=4096, activation=\"relu\"))\n",
        "model.add(Dense(units=2, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "jsgiaKinx1sj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "-ZhLS7_zzpxC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=1, batch_size=128, validation_split=0.2)"
      ],
      "metadata": {
        "id": "jQCQEVElzvOS",
        "outputId": "80d395b6-76ef-4395-b318-2e6e5d456042",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 2455s 16s/step - loss: 0.6961 - accuracy: 0.5018 - val_loss: 0.6932 - val_accuracy: 0.4860\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79adb6a4faf0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, accuracy1 = model.evaluate(X_train, y_train)\n",
        "\n",
        "print(f\"El Accuracy: {accuracy1}\")"
      ],
      "metadata": {
        "id": "bJ85O8z24Nno",
        "outputId": "c3368daa-b2e4-4925-b37b-6db17daad6ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 380s 485ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "El Accuracy: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicción del modelo"
      ],
      "metadata": {
        "id": "eXccCCLg4Tfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test=model.predict(X_test)"
      ],
      "metadata": {
        "id": "FTN99zyM4WzY",
        "outputId": "873811ad-1a4a-4646-81c0-de9ee7f3c2a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "391/391 [==============================] - 192s 488ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Debido al costo computacional solo pudimos realizar el entrenamiento del modelo con epochs=1 logrando un Accuracy de 0.5"
      ],
      "metadata": {
        "id": "G511Xah84bDA"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}